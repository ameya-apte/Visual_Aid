{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import face_recognition\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# # ap.add_argument(\"-e\", \"--encodings\",\n",
    "# # \thelp=\"encodings.pickle\")\n",
    "# ap.add_argument(\"-o\", \"--output\", type=str,\n",
    "# \thelp=\"path to output video\")\n",
    "# ap.add_argument(\"-y\", \"--display\", type=int, default=1,\n",
    "# \thelp=\"whether or not to display output frame to screen\")\n",
    "# ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"hog\",\n",
    "# \thelp=\"face detection model to use: either `hog` or `cnn`\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# load the known faces and embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading encodings...\n",
      "[INFO] starting video stream...\n",
      "person detected is Unknown\n",
      "person detected is Akhilesh\n",
      "person detected is Akhilesh\n",
      "person detected is Unknown\n",
      "person detected is Ameya\n",
      "person detected is Akhilesh\n",
      "person detected is Ameya\n",
      "person detected is Akhilesh\n",
      "person detected is Ameya\n",
      "person detected is Akhilesh\n",
      "person detected is Akhilesh\n",
      "person detected is Ameya\n",
      "person detected is Ameya\n",
      "person detected is Akhilesh\n",
      "person detected is Ameya\n",
      "person detected is Akhilesh\n",
      "person detected is Ameya\n",
      "person detected is Akhilesh\n",
      "person detected is Akhilesh\n",
      "person detected is Ameya\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(\"encodings.pickle\", \"rb\").read())\n",
    "\n",
    "# initialize the video stream and pointer to output video file, then\n",
    "# allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "# vs = VideoStream(src=2).start()\n",
    "# writer = None\n",
    "# time.sleep(1.0)\n",
    "\n",
    "# loop over frames from the video file stream\n",
    "\n",
    "\t# grab the frame from the threaded video stream\n",
    "# \tframe = vs.read()\n",
    "def recognize(frame): \n",
    "\t# convert the input frame from BGR to RGB then resize it to have\n",
    "\t# a width of 750px (to speedup processing)\n",
    "\trgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\trgb = imutils.resize(frame, width=750)\n",
    "\tr = frame.shape[1] / float(rgb.shape[1])\n",
    "\n",
    "\t# detect the (x, y)-coordinates of the bounding boxes\n",
    "\t# corresponding to each face in the input frame, then compute\n",
    "\t# the facial embeddings for each face\n",
    "\tboxes = face_recognition.face_locations(rgb,\n",
    "\t\tmodel=\"hog\")\n",
    "\tencodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\tnames = []\n",
    "\n",
    "\t# loop over the facial embeddings\n",
    "\tfor encoding in encodings:\n",
    "\t\t# attempt to match each face in the input image to our known\n",
    "\t\t# encodings\n",
    "\t\tmatches = face_recognition.compare_faces(data[\"encodings\"],\n",
    "\t\t\tencoding)\n",
    "\t\tname = \"Unknown\"\n",
    "#     print(\"AKHILESH\")\n",
    "\t\t# check to see if we have found a match\n",
    "\t\tif True in matches:\n",
    "\t\t\t# find the indexes of all matched faces then initialize a\n",
    "\t\t\t# dictionary to count the total number of times each face\n",
    "\t\t\t# was matched\n",
    "\t\t\tmatchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "\t\t\tcounts = {}\n",
    "\n",
    "\t\t\t# loop over the matched indexes and maintain a count for\n",
    "\t\t\t# each recognized face face\n",
    "\t\t\tfor i in matchedIdxs:\n",
    "\t\t\t\tname = data[\"names\"][i]\n",
    "\t\t\t\tcounts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "\t\t\t# determine the recognized face with the largest number\n",
    "\t\t\t# of votes (note: in the event of an unlikely tie Python\n",
    "\t\t\t# will select first entry in the dictionary)\n",
    "\t\t\tname = max(counts, key=counts.get)\n",
    "\t\t\n",
    "\t\t# update the list of names\n",
    "\t\tnames.append(name)\n",
    "    return names\n",
    "# \t# loop over the recognized faces\n",
    "# \tfor ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "# \t\t# rescale the face coordinates\n",
    "# \t\ttop = int(top * r)\n",
    "# \t\tright = int(right * r)\n",
    "# \t\tbottom = int(bottom * r)\n",
    "# \t\tleft = int(left * r)\n",
    "\n",
    "# \t\t# draw the predicted face name on the image\n",
    "# \t\tcv2.rectangle(frame, (left, top), (right, bottom),\n",
    "# \t\t\t(0, 255, 0), 2)\n",
    "# \t\ty = top - 15 if top - 15 > 15 else top + 15\n",
    "# \t\tcv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "# \t\t\t0.75, (0, 255, 0), 2)\n",
    "# # \t\tprint('person detected is {}'.format(name))\n",
    "\n",
    "# \t# if the video writer is None *AND* we are supposed to write\n",
    "# \t# the output video to disk initialize the writer\n",
    "# # \tif writer is None and args[\"output\"] is not None:\n",
    "# # \t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "# # \t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 20,\n",
    "# # \t\t\t(frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "# \t# if the writer is not None, write the frame with recognized\n",
    "# \t# faces t odisk\n",
    "# \tif writer is not None:\n",
    "# \t\twriter.write(frame)\n",
    "\n",
    "# \t# check to see if we are supposed to display the output frame to\n",
    "# \t# the screen\n",
    "\t\n",
    "# \tcv2.imshow(\"Frame\", frame)\n",
    "# \tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "# \t\t# if the `q` key was pressed, break from the loop\n",
    "# \tif key == ord(\"q\"):\n",
    "# \t\t\tbreak\n",
    "\n",
    "# # do a bit of cleanup\n",
    "# cv2.destroyAllWindows()\n",
    "# vs.stop()\n",
    "\n",
    "# # check to see if the video writer point needs to be released\n",
    "# if writer is not None:\n",
    "# \twriter.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
